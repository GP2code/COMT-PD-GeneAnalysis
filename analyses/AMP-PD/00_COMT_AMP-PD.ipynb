{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# COMT - Single gene analysis in the AMP-PD data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Project: COMT Single Gene analysis\n",
    "- Version: Python/3.10.12\n",
    "- Last Updated: 01-APRIL-2025\n",
    "- Update Description: Clean code and adding some minor comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook overview\n",
    "In this notebook we performed regression analyses with COMT gene variants detected in WGS AMP-PD data using PLINK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Description\n",
    "\n",
    "__1. Description__\n",
    "\n",
    "-  Getting Started\n",
    "- Loading Python libraries\n",
    "- Defining functions\n",
    "- Set Paths\n",
    "- Make working directory\n",
    "\n",
    "__2. Installing packages__\n",
    "\n",
    "__3. Copy over data__\n",
    "\n",
    "__4. Create a covariate file with AMP-PD data__\n",
    "\n",
    "__5. Remove related individuals and PCA__\n",
    "\n",
    "__6. Annotation of the gene__\n",
    "\n",
    "__7. Case/Control Analysis__\n",
    "\n",
    "__8. Clinical scales Association Analyses__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Loading Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121/4190448927.py:26: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    }
   ],
   "source": [
    "# Use the os package to interact with the environment\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Bring in Pandas for Dataframe functionality\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "# Bring some visualization functionality \n",
    "import seaborn as sns  \n",
    "\n",
    "# numpy for basics\n",
    "import numpy as np\n",
    "\n",
    "# Use StringIO for working with file contents\n",
    "from io import StringIO\n",
    "\n",
    "# Enable IPython to display matplotlib graphs\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable interaction with the FireCloud API\n",
    "from firecloud import api as fapi\n",
    "\n",
    "# Import the iPython HTML rendering for displaying links to Google Cloud Console\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# Import urllib modules for building URLs to Google Cloud Console\n",
    "import urllib.parse\n",
    "\n",
    "# BigQuery for querying data\n",
    "from google.cloud import bigquery\n",
    "\n",
    "#Import Sys\n",
    "import sys as sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Utility routine for printing a shell command before executing it\n",
    "def shell_do(command):\n",
    "    print(f'Executing: {command}', file=sys.stderr)\n",
    "    !$command\n",
    "    \n",
    "def shell_return(command):\n",
    "    print(f'Executing: {command}', file=sys.stderr)\n",
    "    output = !$command\n",
    "    return '\\n'.join(output)\n",
    "\n",
    "# Utility routine for printing a query before executing it\n",
    "def bq_query(query):\n",
    "    print(f'Executing: {query}', file=sys.stderr)\n",
    "    return pd.read_gbq(query, project_id=BILLING_PROJECT_ID, dialect='standard')\n",
    "\n",
    "# Utility routine for display a message and a link\n",
    "def display_html_link(description, link_text, url):\n",
    "    html = f'''\n",
    "    <p>\n",
    "    </p>\n",
    "    <p>\n",
    "    {description}\n",
    "    <a target=_blank href=\"{url}\">{link_text}</a>.\n",
    "    </p>\n",
    "    '''\n",
    "\n",
    "    display(HTML(html))\n",
    "\n",
    "# Utility routines for reading files from Google Cloud Storage\n",
    "def gcs_read_file(path):\n",
    "    \"\"\"Return the contents of a file in GCS\"\"\"\n",
    "    contents = !gsutil -u {BILLING_PROJECT_ID} cat {path}\n",
    "    return '\\n'.join(contents)\n",
    "    \n",
    "def gcs_read_csv(path, sep=None):\n",
    "    \"\"\"Return a DataFrame from the contents of a delimited file in GCS\"\"\"\n",
    "    return pd.read_csv(StringIO(gcs_read_file(path)), sep=sep, engine='python')\n",
    "\n",
    "# Utility routine for displaying a message and link to Cloud Console\n",
    "def link_to_cloud_console_gcs(description, link_text, gcs_path):\n",
    "    url = '{}?{}'.format(\n",
    "        os.path.join('https://console.cloud.google.com/storage/browser',\n",
    "                     gcs_path.replace(\"gs://\",\"\")),\n",
    "        urllib.parse.urlencode({'userProject': BILLING_PROJECT_ID}))\n",
    "\n",
    "    display_html_link(description, link_text, url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set up billing project and data path variables\n",
    "BILLING_PROJECT_ID = os.environ['GOOGLE_PROJECT']\n",
    "WORKSPACE_NAMESPACE = os.environ['WORKSPACE_NAMESPACE']\n",
    "WORKSPACE_NAME = os.environ['WORKSPACE_NAME']\n",
    "WORKSPACE_BUCKET = os.environ['WORKSPACE_BUCKET']\n",
    "WORKSPACE_ATTRIBUTES = fapi.get_workspace(WORKSPACE_NAMESPACE, WORKSPACE_NAME).json().get('workspace',{}).get('attributes',{})\n",
    "\n",
    "## Print the information to check we are in the proper release and billing \n",
    "## This will be different for you, the user, depending on the billing project your workspace is on\n",
    "print('Billing and Workspace')\n",
    "print(f'Workspace Name @ `WORKSPACE_NAME`: {WORKSPACE_NAME}')\n",
    "print(f'Billing Project @ `BILLING_PROJECT_ID`: {BILLING_PROJECT_ID}')\n",
    "print(f'Workspace Bucket, where you can upload and download data @ `WORKSPACE_BUCKET`: {WORKSPACE_BUCKET}')\n",
    "print('')\n",
    "\n",
    "## AMP-PD v3.0\n",
    "## Explicitly define release v3.0 path \n",
    "AMP_RELEASE_PATH = 'path/'\n",
    "AMP_CLINICAL_RELEASE_PATH = f'{AMP_RELEASE_PATH}/clinical'\n",
    "AMP_RELEASE_GATK_PATH = os.path.join(AMP_RELEASE_PATH, 'gatk')\n",
    "AMP_WGS_RELEASE_PATH = 'path/'\n",
    "AMP_WGS_RELEASE_PLINK_PATH = os.path.join(AMP_WGS_RELEASE_PATH, 'plink')\n",
    "AMP_WGS_RELEASE_PLINK_PFILES = os.path.join(AMP_WGS_RELEASE_PLINK_PATH, 'pfiles')\n",
    "\n",
    "print('AMP-PD v3.0')\n",
    "print(f'Path to AMP-PD v3.0 Clinical Data: {AMP_CLINICAL_RELEASE_PATH}')\n",
    "print(f'Path to AMP-PD v3.0 WGS Data: {AMP_WGS_RELEASE_PLINK_PATH}')\n",
    "print(f'Path to AMP-PD v3.0 WGS Data: {AMP_WGS_RELEASE_PLINK_PFILES}')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Make working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing: mkdir -p /home/jupyter/COMT_AMPPD\n"
     ]
    }
   ],
   "source": [
    "# Make a directory called \"/home/jupyter/COMT_AMPPD/\"\n",
    "WORK_DIR = f'/home/jupyter/COMT_AMPPD'\n",
    "\n",
    "shell_do(f'mkdir -p {WORK_DIR}') # f' means f-string - contains expressions to execute the code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Install Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## PLINK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plink1.9 is already installed in /home/jupyter/tools/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p ~/tools\n",
    "cd ~/tools\n",
    "\n",
    "if test -e /home/jupyter/tools/plink; then\n",
    "echo \"Plink1.9 is already installed in /home/jupyter/tools/\"\n",
    "\n",
    "else\n",
    "echo -e \"Downloading plink \\n    -------\"\n",
    "wget -N http://s3.amazonaws.com/plink1-assets/plink_linux_x86_64_20190304.zip \n",
    "unzip -o plink_linux_x86_64_20190304.zip\n",
    "echo -e \"\\n plink downloaded and unzipped in /home/jupyter/tools \\n \"\n",
    "\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Install plink2. If this doesn't work, get the updated download link from https://www.cog-genomics.org/plink/2.0/, as this changes regularly. We use the download link for Linux AVX2 AMD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plink2 is already installed in /home/jupyter/tools/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p ~/tools\n",
    "cd ~/tools\n",
    "\n",
    "if test -e /home/jupyter/tools/plink2; then\n",
    "echo \"Plink2 is already installed in /home/jupyter/tools/\"\n",
    "\n",
    "else\n",
    "echo -e \"Downloading plink2 \\n    -------\"\n",
    "wget -N https://s3.amazonaws.com/plink2-assets/plink2_linux_amd_avx2_20240806.zip\n",
    "unzip -o plink2_linux_amd_avx2_20240806.zip\n",
    "echo -e \"\\n plink2 downloaded and unzipped in /home/jupyter/tools \\n \"\n",
    "\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## ANNOVAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%bash\n",
    "\n",
    "# https://www.openbioinformatics.org/annovar/annovar_download_form.php\n",
    "\n",
    "if test -e /home/jupyter/tools/annovar; then\n",
    "\n",
    "echo \"annovar is already installed in /home/jupyter/tools/\"\n",
    "else\n",
    "echo \"annovar is not installed\"\n",
    "cd /home/jupyter/tools/\n",
    "\n",
    "wget http://www.openbioinformatics.org/annovar/download/0wgxR2rIVP/annovar.latest.tar.gz\n",
    "\n",
    "tar xvfz annovar.latest.tar.gz\n",
    "\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### ANNOVAR: Download sources of annotation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd /home/jupyter/tools/annovar/\n",
    "\n",
    "perl annotate_variation.pl -buildver hg38 -downdb -webfrom annovar refGene humandb/\n",
    "perl annotate_variation.pl -buildver hg38 -downdb -webfrom annovar clinvar_20170905 humandb/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## RVTests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rvtests is already installed\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "#Install RVTESTS: Option 1 (~15min)\n",
    "if test -e /home/jupyter/tools/rvtests; then\n",
    "\n",
    "echo \"rvtests is already installed\"\n",
    "else\n",
    "echo \"rvtests is not installed\"\n",
    "\n",
    "mkdir /home/jupyter/tools/rvtests\n",
    "cd /home/jupyter/tools/rvtests\n",
    "\n",
    "wget https://github.com/zhanxw/rvtests/releases/download/v2.1.0/rvtests_linux64.tar.gz \n",
    "\n",
    "tar -zxvf rvtests_linux64.tar.gz\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# chmod to make sure you have permission to run the program\n",
    "! chmod u+x /home/jupyter/tools/plink\n",
    "! chmod u+x /home/jupyter/tools/plink2\n",
    "! chmod 777 /home/jupyter/tools/rvtests/executable/rvtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "#Show installed tools\n",
    "ls /home/jupyter/tools/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Copy Over Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Check what is in the main AMP-PD release 3 release path\n",
    "shell_do(f'gsutil -u {BILLING_PROJECT_ID} ls {AMP_RELEASE_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Check what is in the WGS release path\n",
    "shell_do(f'gsutil -u {BILLING_PROJECT_ID} ls {AMP_WGS_RELEASE_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check directory where AMP-PD data is\n",
    "print(\"List available imputed genotype information in AMPPD\")\n",
    "shell_do(f'gsutil -u {BILLING_PROJECT_ID} ls {AMP_WGS_RELEASE_PLINK_PFILES}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "##  Imputed genotype AMP-PD release 3 data\n",
    "# COMT coordinates: chr22:19,941,371-19,969,975(GRCh38/hg38) https://www.genecards.org/cgi-bin/carddisp.pl?gene=COMT\n",
    "WORK_DIR = f'/home/jupyter/COMT_AMPPD'\n",
    "\n",
    "shell_do(f'gsutil -u {BILLING_PROJECT_ID} -m cp {AMP_WGS_RELEASE_PLINK_PFILES}/chr22.* {WORK_DIR}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Copy other AMP-PD files (clinical info)\n",
    "WORK_DIR = f'/home/jupyter/COMT_AMPPD'\n",
    "\n",
    "shell_do(f'gsutil -u {BILLING_PROJECT_ID} -m cp -r {AMP_RELEASE_PATH}/amp_pd_case_control.csv {WORK_DIR}')\n",
    "shell_do(f'gsutil -u {BILLING_PROJECT_ID} -m cp -r {AMP_CLINICAL_RELEASE_PATH}/Enrollment.csv {WORK_DIR}')\n",
    "shell_do(f'gsutil -u {BILLING_PROJECT_ID} -m cp -r {AMP_CLINICAL_RELEASE_PATH}/Demographics.csv {WORK_DIR}')\n",
    "shell_do(f'gsutil -u {BILLING_PROJECT_ID} -m cp -r {AMP_CLINICAL_RELEASE_PATH}/PD_Medical_History.csv  {WORK_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## refFlat\n",
    "WORK_DIR = f'/home/jupyter/COMT_AMPPD'\n",
    "\n",
    "shell_do(f'gsutil -u {BILLING_PROJECT_ID} -m cp -r {WORKSPACE_BUCKET}/refFlat.txt.gz {WORK_DIR}')\n",
    "!gzip -d {WORK_DIR}/refFlat.txt.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd $WORK_DIR\n",
    "\n",
    "#wget https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz\n",
    "#gunzip -k hg38.fa.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create a covariate file with AMP-PD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load clinical information\n",
    "pd_case_control_df = pd.read_csv(f'{WORK_DIR}/amp_pd_case_control.csv')\n",
    "\n",
    "# visualize\n",
    "#pd_case_control_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Keep columns of interest\n",
    "pd_case_control_latest_df = pd_case_control_df[['participant_id', 'diagnosis_latest', 'case_control_other_latest']].copy()\n",
    "\n",
    "# Rename Columns\n",
    "pd_case_control_latest_df.columns = ['ID', 'LATEST_DX', 'CASE_CONTROL']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASE_CONTROL\n",
      "Control    4337\n",
      "Case       3538\n",
      "Other      2933\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check case/control value counts\n",
    "print(pd_case_control_latest_df['CASE_CONTROL'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Add column for study origin\n",
    "pd_case_control_latest_df['COHORT']= np.where(pd_case_control_latest_df.ID.str.contains(\"LB-\"), \"LBD\",\n",
    "                                    np.where(pd_case_control_latest_df.ID.str.contains(\"PP-\"), \"PPMI\",\n",
    "                                    np.where(pd_case_control_latest_df.ID.str.contains(\"PD-\"), \"PDBP\",\n",
    "                                    np.where(pd_case_control_latest_df.ID.str.contains(\"HB-\"), \"HBS\",\n",
    "                                    np.where(pd_case_control_latest_df.ID.str.contains(\"LC-\"), \"LCC\",\n",
    "                                    np.where(pd_case_control_latest_df.ID.str.contains(\"BF-\"), \"BIOFIND\",\n",
    "                                    np.where(pd_case_control_latest_df.ID.str.contains(\"SU-\"), \"SURE-PD3\",\n",
    "                                    np.where(pd_case_control_latest_df.ID.str.contains(\"SY-\"), \"STEADY-PD3\", np.nan))))))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "case_con_reduced = pd_case_control_latest_df.copy()\n",
    "case_con_reduced.drop_duplicates(subset=['ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Assign case control for Plink\n",
    "conditions = [\n",
    "    (case_con_reduced['CASE_CONTROL'] == \"Case\"),\n",
    "    (case_con_reduced['CASE_CONTROL'] == \"Control\")]\n",
    "## Assign cases=2, controls=1, -9 Other (as used in PLINK)\n",
    "choices = [2,1]\n",
    "case_con_reduced['PHENO'] = np.select(conditions, choices, default=-9).astype(np.int64)\n",
    "\n",
    "# set indices\n",
    "case_con_reduced.reset_index(inplace=True)\n",
    "case_con_reduced.drop(columns=[\"index\"], inplace=True)\n",
    "\n",
    "# Remove initial Pheno Column\n",
    "case_con_reduced.drop(columns=['CASE_CONTROL'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHENO\n",
      " 1    4337\n",
      " 2    3537\n",
      "-9    2933\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Phenotype counts\n",
    "print(case_con_reduced['PHENO'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load Enrollment.csv\n",
    "enrollment_df = pd.read_csv(f'{WORK_DIR}/Enrollment.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Keep columns of interest\n",
    "enrollment_subset_df = enrollment_df[['participant_id', 'study_arm']].copy()\n",
    "\n",
    "# Rename columns\n",
    "enrollment_subset_df.columns = ['ID', 'ENROLL_STUDY_ARM']\n",
    "enrollment_subset_df.head()\n",
    "\n",
    "# Drop duplicates\n",
    "enrollment_subset_df.drop_duplicates(subset=['ID'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load demographic data\n",
    "demographics_df = pd.read_csv(f'{WORK_DIR}/Demographics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Rename Columns\n",
    "demographics_df.rename(columns = {'participant_id':'ID'}, inplace = True)\n",
    "demographics_df.rename(columns = {'age_at_baseline':'BASELINE_AGE'}, inplace = True)\n",
    "demographics_df.rename(columns = {'race':'RACE'}, inplace = True)\n",
    "demographics_df.rename(columns = {'ethnicity':'ETHNICITY'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Sort by visit month and Drop Duplicates\n",
    "demographics_baseline_df = demographics_df \\\n",
    ".sort_values('visit_month', ascending=True) \\\n",
    ".drop_duplicates('ID').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Merge last diagnostic with diagnostic at enrollement\n",
    "demographics_df_casecon = demographics_df.merge(case_con_reduced, on='ID', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Recode Sex Columns\n",
    "conditions = [\n",
    "     (demographics_df_casecon['sex'] == \"Male\"),\n",
    "     (demographics_df_casecon['sex'] == \"Female\")]\n",
    "\n",
    "# 1=Male; 2=Female\n",
    "choices = [1,2]\n",
    "\n",
    "# Create new column Sex\n",
    "demographics_df_casecon['SEX'] = np.select(conditions, choices, default=None).astype(np.int64)\n",
    "\n",
    "# Remove previous Sex column\n",
    "demographics_df_casecon.drop(columns=['sex'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Keep only columns of interest\n",
    "demographics_df_casecon_toKeep = demographics_df_casecon[['ID', 'PHENO', 'SEX', 'RACE',\n",
    "                                                          'ETHNICITY','BASELINE_AGE', 'LATEST_DX',\n",
    "                                                          'COHORT']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Merge Pheno with demograhic data\n",
    "enrollment_pheno_df = demographics_df_casecon_toKeep.merge(enrollment_subset_df, on='ID', how='outer')\n",
    "\n",
    "# Create FID column\n",
    "enrollment_pheno_df['FID'] = enrollment_pheno_df['ID'].values\n",
    "\n",
    "# rename ID as IID \n",
    "enrollment_pheno_df.rename(columns = {'ID':'IID'}, inplace = True)\n",
    "\n",
    "# Order columns\n",
    "reorder_enrollment_pheno_df = enrollment_pheno_df[['FID', 'IID', 'PHENO',\n",
    "                                                  'SEX', 'RACE','ETHNICITY', 'BASELINE_AGE', 'LATEST_DX',\n",
    "                                                  'COHORT', 'ENROLL_STUDY_ARM']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Remove individuals from the genetic registry cohorts and other enrollment categories\n",
    "#We only want to keep  controls who were originally enrolled as controls, and PD cases originally enrolled as cases\n",
    "#Will exclude prodromal, SWEDD and unknown individuals also\n",
    "#Individuals enrolled as disease control but the latest diagnosis is PD will also be excluded\n",
    "\n",
    "#Keep only individuals enrolled as Healthy Control/Disease Control or PD.\n",
    "filtered_enrollment_pheno_df = reorder_enrollment_pheno_df.copy()\n",
    "filtered_enrollment_pheno_df = filtered_enrollment_pheno_df[filtered_enrollment_pheno_df['ENROLL_STUDY_ARM'].isin(['Disease Control', \n",
    "                                                                                                                   'Healthy Control', \n",
    "                                                                                                                  'PD'])]\n",
    "#Now remove individuals with PHENO of -9 (keep only individuals with PHENO of 1 or 2)\n",
    "filtered_enrollment_pheno_df = filtered_enrollment_pheno_df[filtered_enrollment_pheno_df['PHENO'].isin([1,2])]\n",
    "\n",
    "#Now remove individuals who were enrolled with the opposite diagnosis, i.e. individuals who were enrolled as controls but have a latest diagnosis of PD\n",
    "filtered_enrollment_pheno_df = filtered_enrollment_pheno_df[((filtered_enrollment_pheno_df['PHENO'] == 2) & (filtered_enrollment_pheno_df['ENROLL_STUDY_ARM'] == 'PD')) | (filtered_enrollment_pheno_df['PHENO'] == 1)]\n",
    "\n",
    "\n",
    "#Check value counts again\n",
    "filtered_enrollment_pheno_df.groupby(['PHENO', 'ENROLL_STUDY_ARM']).size().reset_index(name='counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save file - this is intermediate not final covariate file\n",
    "#This includes all ancestries\n",
    "filtered_enrollment_pheno_df.to_csv(f'{WORK_DIR}/COVS_temp.txt', index=False, sep='\\t', na_rep='NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Import GenoTools ancestry\n",
    "\n",
    "This is needed for the ancestry labels. Need to do this before running the PCA as the PCs should be generated just in the population/group of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shell_do(f'gsutil -u {BILLING_PROJECT_ID} -m cp -r {WORKSPACE_BUCKET}/AMPPD_v3_COV_wPHENOS_wGENOTOOLS.csv {WORK_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read covariate file to get ancestry groups\n",
    "ancestries = pd.read_csv(f'{WORK_DIR}/AMPPD_v3_COV_wPHENOS_wGENOTOOLS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#This file has a lot of the diagnosis info that we have generated ourselves earlier.\n",
    "#We just want the ancestry label (the last column)\n",
    "\n",
    "ancestries_selected = ancestries[['ID', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Filter for ancestry of interest\n",
    "#Change this to your ancestry of interest\n",
    "ancestry_toKeep = 'EUR'\n",
    "\n",
    "ancestries_keep = ancestries_selected.copy()\n",
    "ancestries_keep = ancestries_selected[ancestries_selected['label'] == ancestry_toKeep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "EUR    8607\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the value counts again - this should just be the ancestry you are interested in\n",
    "ancestries_keep.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Merge covariate file with the ancestry file\n",
    "#Inner join - meaning we only want to keep individuals in both dataframes\n",
    "#So this will keep just individuals in the selected ancestry group\n",
    "merged = pd.merge(filtered_enrollment_pheno_df, ancestries_keep, left_on = 'IID', right_on = 'ID', how = 'inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Write list of individuals from the ancestry group of interest to keep from the genetic dataset\n",
    "#We need to do this before generating PCs\n",
    "individuals_toKeep = merged[['FID', 'IID']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Export file\n",
    "#Note this still has related individuals\n",
    "#We will remove related individuals at the next step\n",
    "individuals_toKeep.to_csv('/home/jupyter/COMT_AMPPD/individuals_toKeep.EUR_enroll.txt', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove related individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the workspace bucket, copy over the file with EUR related individuals to remove (just one individual from each pair)\n",
    "#Make sure to copy over the file for the correct ancestry\n",
    "shell_do(f'gsutil -u {BILLING_PROJECT_ID} -m cp -r {WORKSPACE_BUCKET}/toRemove_1stand2ndDegree_Relateds_EUR.txt {WORK_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v2.0.0-a.6.9LM AVX2 AMD (29 Jan 2025)        cog-genomics.org/plink/2.0/\n",
      "(C) 2005-2025 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to /home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.log.\n",
      "Options in effect:\n",
      "  --keep /home/jupyter/COMT_AMPPD/individuals_toKeep.EUR_enroll.txt\n",
      "  --make-bed\n",
      "  --max-alleles 2\n",
      "  --out /home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll\n",
      "  --pfile /home/jupyter/COMT_AMPPD/chr22\n",
      "  --remove /home/jupyter/COMT_AMPPD/toRemove_1stand2ndDegree_Relateds_EUR.txt\n",
      "\n",
      "Start time: Tue Apr  1 14:43:23 2025\n",
      "7445 MiB RAM detected, ~6123 available; reserving 3722 MiB for main workspace.\n",
      "Using up to 2 compute threads.\n",
      "10418 samples (0 females, 0 males, 10418 ambiguous; 10418 founders) loaded from\n",
      "/home/jupyter/COMT_AMPPD/chr22.psam.\n",
      "1938650 out of 2159838 variants loaded from\n",
      "/home/jupyter/COMT_AMPPD/chr22.pvar.\n",
      "Note: No phenotype data present.\n",
      "--keep: 5174 samples remaining.\n",
      "--remove: 5086 samples remaining.\n",
      "Warning: At least 39 duplicate IDs in --remove file(s).\n",
      "5086 samples (0 females, 0 males, 5086 ambiguous; 5086 founders) remaining\n",
      "after main filters.\n",
      "1938650 variants remaining after main filters.\n",
      "Writing /home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.fam ... done.\n",
      "Writing /home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.bim ... done.\n",
      "Writing /home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.bed ... 1114172023262933363942454851545760636770737679828588919497done.\n",
      "End time: Tue Apr  1 14:45:07 2025\n"
     ]
    }
   ],
   "source": [
    "# Remove related individuals and keep only PD and controls in the correct enrollment categories\n",
    "# Used make-bed not make-pgen because there is a bug in plink2 and it doesn't write the pgen file https://groups.google.com/g/plink2-users/c/z_ZVhacpnts/m/byzJxGl5AwAJ\n",
    "# Have included max-alleles 2 because plink cannot write bim file with multialleleic variants\n",
    "WORK_DIR = f'/home/jupyter/COMT_AMPPD'\n",
    "! /home/jupyter/tools/plink2 \\\n",
    "--pfile {WORK_DIR}/chr22 \\\n",
    "--keep {WORK_DIR}/individuals_toKeep.EUR_enroll.txt \\\n",
    "--remove {WORK_DIR}/toRemove_1stand2ndDegree_Relateds_EUR.txt \\\n",
    "--make-bed \\\n",
    "--max-alleles 2 \\\n",
    "--out {WORK_DIR}/chr22_nonrelated_enroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download from workspace bucket \n",
    "shell_do(f'gsutil -mu {BILLING_PROJECT_ID} cp -r {WORKSPACE_BUCKET}/AMPPD_EUR.COVS.txt {WORK_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update sex and pheno info in plink genetic files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v2.0.0-a.6.9LM AVX2 AMD (29 Jan 2025)        cog-genomics.org/plink/2.0/\n",
      "(C) 2005-2025 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to /home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.updated.log.\n",
      "Options in effect:\n",
      "  --bfile /home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll\n",
      "  --make-pgen\n",
      "  --out /home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.updated\n",
      "  --pheno /home/jupyter/COMT_AMPPD/AMPPD_EUR.COVS.txt\n",
      "  --pheno-name PHENO\n",
      "  --update-sex /home/jupyter/COMT_AMPPD/AMPPD_EUR.COVS.txt col-num=5\n",
      "\n",
      "Start time: Tue Apr  1 14:45:16 2025\n",
      "7445 MiB RAM detected, ~6079 available; reserving 3722 MiB for main workspace.\n",
      "Using up to 2 compute threads.\n",
      "5086 samples (0 females, 0 males, 5086 ambiguous; 5086 founders) loaded from\n",
      "/home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.fam.\n",
      "1938650 variants loaded from\n",
      "/home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.bim.\n",
      "1 binary phenotype loaded (2251 cases, 2835 controls).\n",
      "--update-sex: 5086 samples updated, 1 ID not present.\n",
      "Writing /home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.updated.psam ... done.\n",
      "Writing /home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.updated.pvar ... 101011121213141415161617181819202021222223242425262627282829303031323233343435363637383839404041424243444445464647484849505051525253545455565657585859606061626263646465666667686869707071727273747475767677787879808081828283848485868687888889909091929293949495969697989899done.\n",
      "Writing /home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.updated.pgen ... 13202733404754606774818794done.\n",
      "End time: Tue Apr  1 14:45:21 2025\n"
     ]
    }
   ],
   "source": [
    "# Update sex and phenotype in plink files, using the AMPPD_EUR.COVS.txt file that we made\n",
    "#-update-sex and column number tells plink where to look for the sex information in the file\n",
    "\n",
    "WORK_DIR = f'/home/jupyter/COMT_AMPPD'\n",
    "\n",
    "! /home/jupyter/tools/plink2 \\\n",
    "--bfile {WORK_DIR}/chr22_nonrelated_enroll \\\n",
    "--update-sex {WORK_DIR}/AMPPD_EUR.COVS.txt col-num=5 \\\n",
    "--pheno {WORK_DIR}/AMPPD_EUR.COVS.txt \\\n",
    "--pheno-name PHENO \\\n",
    "--make-pgen \\\n",
    "--out {WORK_DIR}/chr22_nonrelated_enroll.updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Extract and annotate the gene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Extract the region using PLINK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v2.0.0-a.6.9LM AVX2 AMD (29 Jan 2025)        cog-genomics.org/plink/2.0/\n",
      "(C) 2005-2025 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to /home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.updated_formatted.log.\n",
      "Options in effect:\n",
      "  --fa /home/jupyter/hg38.fa\n",
      "  --make-pgen\n",
      "  --memory 25000\n",
      "  --new-id-max-allele-len 999\n",
      "  --out /home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.updated_formatted\n",
      "  --pfile /home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.updated\n",
      "  --set-all-var-ids chr@:#:$r:$a\n",
      "  --sort-vars\n",
      "\n",
      "Start time: Fri Mar 14 15:51:08 2025\n",
      "7445 MiB RAM detected, ~6206 available; reserving 6142 MiB for main workspace.\n",
      "Using up to 2 compute threads.\n",
      "5086 samples (2283 females, 2803 males; 5086 founders) loaded from\n",
      "/home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.updated.psam.\n",
      "1938650 variants loaded from\n",
      "/home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.updated.pvar.\n",
      "1 binary phenotype loaded (2251 cases, 2835 controls).\n",
      "--fa: Length scraped for 1 contig.\n",
      "Writing /home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.updated_formatted.pvar\n",
      "... done.\n",
      "Writing /home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.updated_formatted.psam\n",
      "... done.\n",
      "Writing /home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.updated_formatted.pgen\n",
      "... 101316202327303337404347505457606467707477818487919498done.\n",
      "End time: Fri Mar 14 15:52:02 2025\n"
     ]
    }
   ],
   "source": [
    "## update the variant IDs\n",
    "! /home/jupyter/tools/plink2 \\\n",
    "--pfile /home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.updated \\\n",
    "--fa /home/jupyter/hg38.fa \\\n",
    "--memory 25000 \\\n",
    "--set-all-var-ids \"chr@:#:\\$r:\\$a\" \\\n",
    "--new-id-max-allele-len 999 --sort-vars \\\n",
    "--make-pgen \\\n",
    "--out /home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.updated_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v2.0.0-a.6.9LM AVX2 AMD (29 Jan 2025)        cog-genomics.org/plink/2.0/\n",
      "(C) 2005-2025 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to /home/jupyter/COMT_AMPPD/COMT.log.\n",
      "Options in effect:\n",
      "  --chr 22\n",
      "  --from-bp 19941371\n",
      "  --geno 0.05\n",
      "  --mac 2\n",
      "  --make-pgen\n",
      "  --max-alleles 2\n",
      "  --out /home/jupyter/COMT_AMPPD/COMT\n",
      "  --pfile /home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.updated_formatted\n",
      "  --to-bp 19969975\n",
      "\n",
      "Start time: Fri Mar 14 15:52:04 2025\n",
      "7445 MiB RAM detected, ~6061 available; reserving 3722 MiB for main workspace.\n",
      "Using up to 2 compute threads.\n",
      "5086 samples (2283 females, 2803 males; 5086 founders) loaded from\n",
      "/home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.updated_formatted.psam.\n",
      "1938650 variants loaded from\n",
      "/home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.updated_formatted.pvar.\n",
      "1 binary phenotype loaded (2251 cases, 2835 controls).\n",
      "Calculating allele frequencies... done.\n",
      "--geno: 3 variants removed due to missing genotype data.\n",
      "1176 variants removed due to allele frequency threshold(s)\n",
      "(--maf/--max-maf/--mac/--max-mac).\n",
      "502 variants remaining after main filters.\n",
      "Writing /home/jupyter/COMT_AMPPD/COMT.psam ... done.\n",
      "Writing /home/jupyter/COMT_AMPPD/COMT.pvar ... 10101111121213131414151516161717181819192020212122222323242425252626272728282929303031313232333334343535363637373838393940404141424243434444454546464747484849505051515252535354545555565657575858595960606161626263636464656566666767686869697070717172727373747475757676777778787979808081818282838384848585868687878888898990909191929293939494959596969797989899done.\n",
      "Writing /home/jupyter/COMT_AMPPD/COMT.pgen ... done.\n",
      "End time: Fri Mar 14 15:52:04 2025\n"
     ]
    }
   ],
   "source": [
    "## Chromosome 22: 19,941,371-19,969,975\n",
    "## extract region using plink and make pgen files\n",
    "WORK_DIR = f'/home/jupyter/COMT_AMPPD'\n",
    "\n",
    "! /home/jupyter/tools/plink2 \\\n",
    "--pfile {WORK_DIR}/chr22_nonrelated_enroll.updated_formatted \\\n",
    "--chr 22 \\\n",
    "--from-bp 19941371 \\\n",
    "--to-bp 19969975 \\\n",
    "--max-alleles 2 \\\n",
    "--mac 2 \\\n",
    "--geno 0.05 \\\n",
    "--make-pgen \\\n",
    "--out {WORK_DIR}/COMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v2.0.0-a.6.9LM AVX2 AMD (29 Jan 2025)        cog-genomics.org/plink/2.0/\n",
      "(C) 2005-2025 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to /home/jupyter/COMT_AMPPD/COMT.log.\n",
      "Options in effect:\n",
      "  --chr 22\n",
      "  --from-bp 19941371\n",
      "  --geno 0.05\n",
      "  --mac 2\n",
      "  --make-bed\n",
      "  --max-alleles 2\n",
      "  --out /home/jupyter/COMT_AMPPD/COMT\n",
      "  --pfile /home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.updated_formatted\n",
      "  --to-bp 19969975\n",
      "\n",
      "Start time: Fri Mar 14 15:52:05 2025\n",
      "7445 MiB RAM detected, ~6081 available; reserving 3722 MiB for main workspace.\n",
      "Using up to 2 compute threads.\n",
      "5086 samples (2283 females, 2803 males; 5086 founders) loaded from\n",
      "/home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.updated_formatted.psam.\n",
      "1938650 variants loaded from\n",
      "/home/jupyter/COMT_AMPPD/chr22_nonrelated_enroll.updated_formatted.pvar.\n",
      "1 binary phenotype loaded (2251 cases, 2835 controls).\n",
      "Calculating allele frequencies... done.\n",
      "--geno: 3 variants removed due to missing genotype data.\n",
      "1176 variants removed due to allele frequency threshold(s)\n",
      "(--maf/--max-maf/--mac/--max-mac).\n",
      "502 variants remaining after main filters.\n",
      "Writing /home/jupyter/COMT_AMPPD/COMT.fam ... done.\n",
      "Writing /home/jupyter/COMT_AMPPD/COMT.bim ... done.\n",
      "Writing /home/jupyter/COMT_AMPPD/COMT.bed ... done.\n",
      "End time: Fri Mar 14 15:52:05 2025\n"
     ]
    }
   ],
   "source": [
    "## Extract COMT region using plink and make also binary files\n",
    "WORK_DIR = f'/home/jupyter/COMT_AMPPD'\n",
    "\n",
    "! /home/jupyter/tools/plink2 \\\n",
    "--pfile {WORK_DIR}/chr22_nonrelated_enroll.updated_formatted \\\n",
    "--chr 22 \\\n",
    "--from-bp 19941371 \\\n",
    "--to-bp 19969975 \\\n",
    "--max-alleles 2 \\\n",
    "--mac 2 \\\n",
    "--geno 0.05 \\\n",
    "--make-bed \\\n",
    "--out {WORK_DIR}/COMT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Turn binary files into VCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v2.0.0-a.6.9LM AVX2 AMD (29 Jan 2025)        cog-genomics.org/plink/2.0/\r\n",
      "(C) 2005-2025 Shaun Purcell, Christopher Chang   GNU General Public License v3\r\n",
      "Logging to /home/jupyter/COMT_AMPPD/COMT.log.\r\n",
      "Options in effect:\r\n",
      "  --bfile /home/jupyter/COMT_AMPPD/COMT\r\n",
      "  --export vcf id-paste=iid\r\n",
      "  --out /home/jupyter/COMT_AMPPD/COMT\r\n",
      "\r\n",
      "Start time: Fri Mar 14 15:53:56 2025\r\n",
      "7445 MiB RAM detected, ~6095 available; reserving 3722 MiB for main workspace.\r\n",
      "Using up to 2 compute threads.\r\n",
      "5086 samples (2283 females, 2803 males; 5086 founders) loaded from\r\n",
      "/home/jupyter/COMT_AMPPD/COMT.fam.\r\n",
      "502 variants loaded from /home/jupyter/COMT_AMPPD/COMT.bim.\r\n",
      "1 binary phenotype loaded (2251 cases, 2835 controls).\r\n",
      "--export vcf to /home/jupyter/COMT_AMPPD/COMT.vcf ... 0%\b\b0%\b\b1%\b\b1%\b\b2%\b\b2%\b\b3%\b\b3%\b\b4%\b\b4%\b\b5%\b\b5%\b\b6%\b\b6%\b\b7%\b\b7%\b\b8%\b\b8%\b\b9%\b\b9%\b\b10%\b\b\b10%\b\b\b11%\b\b\b11%\b\b\b12%\b\b\b12%\b\b\b13%\b\b\b13%\b\b\b14%\b\b\b14%\b\b\b15%\b\b\b15%\b\b\b16%\b\b\b16%\b\b\b17%\b\b\b17%\b\b\b18%\b\b\b18%\b\b\b19%\b\b\b19%\b\b\b20%\b\b\b20%\b\b\b21%\b\b\b21%\b\b\b22%\b\b\b22%\b\b\b23%\b\b\b23%\b\b\b24%\b\b\b24%\b\b\b25%\b\b\b25%\b\b\b26%\b\b\b26%\b\b\b27%\b\b\b27%\b\b\b28%\b\b\b28%\b\b\b29%\b\b\b29%\b\b\b30%\b\b\b30%\b\b\b31%\b\b\b31%\b\b\b32%\b\b\b32%\b\b\b33%\b\b\b33%\b\b\b34%\b\b\b34%\b\b\b35%\b\b\b35%\b\b\b36%\b\b\b36%\b\b\b37%\b\b\b37%\b\b\b38%\b\b\b38%\b\b\b39%\b\b\b39%\b\b\b40%\b\b\b40%\b\b\b41%\b\b\b41%\b\b\b42%\b\b\b42%\b\b\b43%\b\b\b43%\b\b\b44%\b\b\b44%\b\b\b45%\b\b\b45%\b\b\b46%\b\b\b46%\b\b\b47%\b\b\b47%\b\b\b48%\b\b\b48%\b\b\b49%\b\b\b50%\b\b\b50%\b\b\b51%\b\b\b51%\b\b\b52%\b\b\b52%\b\b\b53%\b\b\b53%\b\b\b54%\b\b\b54%\b\b\b55%\b\b\b55%\b\b\b56%\b\b\b56%\b\b\b57%\b\b\b57%\b\b\b58%\b\b\b58%\b\b\b59%\b\b\b59%\b\b\b60%\b\b\b60%\b\b\b61%\b\b\b61%\b\b\b62%\b\b\b62%\b\b\b63%\b\b\b63%\b\b\b64%\b\b\b64%\b\b\b65%\b\b\b65%\b\b\b66%\b\b\b66%\b\b\b67%\b\b\b67%\b\b\b68%\b\b\b68%\b\b\b69%\b\b\b69%\b\b\b70%\b\b\b70%\b\b\b71%\b\b\b71%\b\b\b72%\b\b\b72%\b\b\b73%\b\b\b73%\b\b\b74%\b\b\b74%\b\b\b75%\b\b\b75%\b\b\b76%\b\b\b76%\b\b\b77%\b\b\b77%\b\b\b78%\b\b\b78%\b\b\b79%\b\b\b79%\b\b\b80%\b\b\b80%\b\b\b81%\b\b\b81%\b\b\b82%\b\b\b82%\b\b\b83%\b\b\b83%\b\b\b84%\b\b\b84%\b\b\b85%\b\b\b85%\b\b\b86%\b\b\b86%\b\b\b87%\b\b\b87%\b\b\b88%\b\b\b88%\b\b\b89%\b\b\b89%\b\b\b90%\b\b\b90%\b\b\b91%\b\b\b91%\b\b\b92%\b\b\b92%\b\b\b93%\b\b\b93%\b\b\b94%\b\b\b94%\b\b\b95%\b\b\b95%\b\b\b96%\b\b\b96%\b\b\b97%\b\b\b97%\b\b\b98%\b\b\b98%\b\b\b99%\b\b\bdone.\r\n",
      "End time: Fri Mar 14 15:53:56 2025\r\n"
     ]
    }
   ],
   "source": [
    "## Turn binary files into VCF\n",
    "WORK_DIR = f'/home/jupyter/COMT_AMPPD'\n",
    "! /home/jupyter/tools/plink2 \\\n",
    "--bfile {WORK_DIR}/COMT \\\n",
    "--recode vcf id-paste=iid \\\n",
    "--out {WORK_DIR}/COMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Bgzip and Tabix (zip and index the file)\n",
    "\n",
    "! bgzip -f {WORK_DIR}/COMT.vcf\n",
    "! tabix -f -p vcf {WORK_DIR}/COMT.vcf.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Annotate using ANNOVAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I have included with the dbnsfp47a database which includes the CADD scores. The ANNOVAR tutorial uses v3.0 of the dbNSFP database (https://annovar.openbioinformatics.org/en/latest/user-guide/startup/#a-useful-tutorial) but dbNSFP v4.7 is the latest version (see http://database.liulab.science/dbNSFP#version). The 4.7a version is the academic version which includes CADD, the commercial version does not include CADD (https://www.biostars.org/p/9573857/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## annotate using ANNOVAR\n",
    "! perl /home/jupyter/tools/annovar/table_annovar.pl {WORK_DIR}/COMT.vcf.gz /home/jupyter/tools/annovar/humandb/ -buildver hg38 \\\n",
    "-out {WORK_DIR}/COMT.annovar \\\n",
    "-remove -protocol refGene,clinvar_20170905 \\\n",
    "-operation g,f \\\n",
    "--nopolish \\\n",
    "-nastring . \\\n",
    "-vcfinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMP-PD\n",
      "Total variants:  491\n",
      "Intronic:  444\n",
      "Upstream:  0\n",
      "Downstream:  0\n",
      "UTR3:  20\n",
      "UTR5:  14\n",
      "Splicing:  0\n",
      "Total exonic:  13\n",
      "Stopgain:  0\n",
      "Stoploss:  0\n",
      "Startloss:  0\n",
      "Frameshift deletion:  0\n",
      "Frameshift insertion:  0\n",
      "Non-frameshift insertion:  0\n",
      "Non-frameshift deletion:  1\n",
      "Synonymous:  8\n",
      "Nonsynonymous:  4\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in ANNOVAR multianno file\n",
    "gene = pd.read_csv(f'{WORK_DIR}/COMT.annovar.hg38_multianno.txt', sep = '\\t')\n",
    "    \n",
    "#Filter for the correct gene name (sometimes other genes are also included)\n",
    "gene = gene[gene['Gene.refGene'] == 'COMT']\n",
    "    \n",
    "#Print number of variants in the different categories\n",
    "results = [] \n",
    "\n",
    "intronic = gene[gene['Func.refGene']== 'intronic']\n",
    "upstream = gene[gene['Func.refGene']== 'upstream']\n",
    "downstream = gene[gene['Func.refGene']== 'downstream']\n",
    "utr5 = gene[gene['Func.refGene']== 'UTR5']\n",
    "utr3 = gene[gene['Func.refGene']== 'UTR3']\n",
    "splicing = gene[gene['Func.refGene']== 'splicing']\n",
    "exonic = gene[gene['Func.refGene']== 'exonic']\n",
    "stopgain = gene[(gene['Func.refGene'] == 'exonic') & (gene['ExonicFunc.refGene'] == 'stopgain')]\n",
    "stoploss = gene[(gene['Func.refGene'] == 'exonic') & (gene['ExonicFunc.refGene'] == 'stoploss')]\n",
    "startloss = gene[(gene['Func.refGene'] == 'exonic') & (gene['ExonicFunc.refGene'] == 'startloss')]\n",
    "frameshift_deletion = gene[(gene['Func.refGene'] == 'exonic') & (gene['ExonicFunc.refGene'] == 'frameshift deletion')]\n",
    "frameshift_insertion = gene[(gene['Func.refGene'] == 'exonic') & (gene['ExonicFunc.refGene'] == 'frameshift insertion')]\n",
    "nonframeshift_deletion = gene[(gene['Func.refGene'] == 'exonic') & (gene['ExonicFunc.refGene'] == 'nonframeshift deletion')]\n",
    "nonframeshift_insertion = gene[(gene['Func.refGene'] == 'exonic') & (gene['ExonicFunc.refGene'] == 'nonframeshift insertion')]\n",
    "coding_nonsynonymous = gene[(gene['Func.refGene'] == 'exonic') & (gene['ExonicFunc.refGene'] == 'nonsynonymous SNV')]\n",
    "coding_synonymous = gene[(gene['Func.refGene'] == 'exonic') & (gene['ExonicFunc.refGene'] == 'synonymous SNV')]\n",
    "        \n",
    "print(\"AMP-PD\")\n",
    "print('Total variants: ', len(gene))\n",
    "print(\"Intronic: \", len(intronic))\n",
    "print(\"Upstream: \", len(upstream))\n",
    "print(\"Downstream: \", len(downstream))\n",
    "print('UTR3: ', len(utr3))\n",
    "print('UTR5: ', len(utr5))\n",
    "print(\"Splicing: \", len(splicing))\n",
    "print(\"Total exonic: \", len(exonic))\n",
    "print(\"Stopgain: \", len(stopgain))\n",
    "print(\"Stoploss: \", len(stoploss))\n",
    "print(\"Startloss: \", len(startloss))\n",
    "print(\"Frameshift deletion: \", len(frameshift_deletion))\n",
    "print(\"Frameshift insertion: \", len(frameshift_insertion))\n",
    "print(\"Non-frameshift insertion: \", len(nonframeshift_insertion))\n",
    "print(\"Non-frameshift deletion: \", len(nonframeshift_deletion))\n",
    "print('Synonymous: ', len(coding_synonymous))\n",
    "print(\"Nonsynonymous: \", len(coding_nonsynonymous))\n",
    "results.append((gene, intronic, upstream, downstream, utr3, utr5, splicing,exonic,stopgain,stoploss,startloss, frameshift_deletion,frameshift_insertion,nonframeshift_deletion,nonframeshift_insertion,coding_synonymous, coding_nonsynonymous))\n",
    "print('\\n')\n",
    "    \n",
    "## For rvtests\n",
    "    \n",
    "# Potential functional: These are variants annotated as frameshift, nonframeshift, startloss, stoploss, stopgain, splicing, missense, exonic, UTR5, UTR3, upstream (-100bp), downstream (+100bp), or ncRNA. \n",
    "potentially_functional = gene[gene['Func.refGene'] != 'intronic']\n",
    "# Coding: These are variants annotated as frameshift, nonframeshift, startloss, stoploss, stopgain, splicing, or missense.\n",
    "coding_variants = gene[(gene['Func.refGene'] == 'splicing') | (gene['Func.refGene'] == 'exonic') & (gene['ExonicFunc.refGene'] != 'synonymous SNV')]\n",
    "# Loss of function: These are variants annotated as frameshift, startloss,stopgain, or splicing.\n",
    "loss_of_function = gene[(gene['Func.refGene'] == 'splicing') | (gene['ExonicFunc.refGene'] == 'stopgain') | (gene['ExonicFunc.refGene'] == 'startloss') | (gene['ExonicFunc.refGene'] == 'frameshift deletion') | (gene['ExonicFunc.refGene'] == 'frameshift insertion')]\n",
    "    \n",
    "# Save in PLINK format\n",
    "variants_toKeep = potentially_functional[['Chr', 'Start', 'End', 'Gene.refGene']].copy()\n",
    "variants_toKeep.to_csv(f'{WORK_DIR}/COMT.potentially_functional.variantstoKeep.txt', sep=\"\\t\", index=False, header=False)\n",
    "\n",
    "variants_toKeep2 = coding_variants[['Chr', 'Start', 'End', 'Gene.refGene']].copy()\n",
    "variants_toKeep2.to_csv(f'{WORK_DIR}/COMT.coding_variants.variantstoKeep.txt', sep=\"\\t\", index=False, header=False)\n",
    "\n",
    "variants_toKeep3 = loss_of_function[['Chr', 'Start', 'End', 'Gene.refGene']].copy()\n",
    "variants_toKeep3.to_csv(f'{WORK_DIR}/COMT.loss_of_function.variantstoKeep.txt', sep=\"\\t\", index=False, header=False)\n",
    "    \n",
    "# For assoc\n",
    "    \n",
    "# These are all exonic variants\n",
    "exonic = gene[gene['Func.refGene'] == 'exonic']\n",
    "    \n",
    "# Save in PLINK format\n",
    "variants_toKeep4 = exonic[['Chr', 'Start', 'End', 'Gene.refGene']].copy()\n",
    "variants_toKeep4.to_csv(f'{WORK_DIR}/COMT.exonic.variantstoKeep.txt', sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Burden Analyses using RVTests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running plink to extract potentially_functional variants for AMP-PD\n",
      "PLINK v2.0.0-a.6.9LM AVX2 AMD (29 Jan 2025)        cog-genomics.org/plink/2.0/\n",
      "(C) 2005-2025 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to /home/jupyter/COMT_AMPPD/AMPPD_COMT.potentially_functional.log.\n",
      "Options in effect:\n",
      "  --export vcf-iid\n",
      "  --extract range /home/jupyter/COMT_AMPPD/COMT.potentially_functional.variantstoKeep.txt\n",
      "  --out /home/jupyter/COMT_AMPPD/AMPPD_COMT.potentially_functional\n",
      "  --pfile /home/jupyter/COMT_AMPPD/COMT\n",
      "\n",
      "Start time: Fri Mar 14 15:56:41 2025\n",
      "Note: --export 'vcf-iid' modifier is deprecated.  Use 'vcf' + 'id-paste=iid'.\n",
      "7445 MiB RAM detected, ~6020 available; reserving 3722 MiB for main workspace.\n",
      "Using up to 2 compute threads.\n",
      "5086 samples (2283 females, 2803 males; 5086 founders) loaded from\n",
      "/home/jupyter/COMT_AMPPD/COMT.psam.\n",
      "502 variants loaded from /home/jupyter/COMT_AMPPD/COMT.pvar.\n",
      "1 binary phenotype loaded (2251 cases, 2835 controls).\n",
      "--extract bed1: 456 variants excluded.\n",
      "46 variants remaining after main filters.\n",
      "--export vcf to /home/jupyter/COMT_AMPPD/AMPPD_COMT.potentially_functional.vcf\n",
      "... 1013151719212326283032343639414345475052545658606365676971737678808284868991939597done.\n",
      "End time: Fri Mar 14 15:56:41 2025\n",
      "Running bgzip and tabix for potentially_functional variants for AMP-PD\n",
      "Running plink to extract coding_variants variants for AMP-PD\n",
      "PLINK v2.0.0-a.6.9LM AVX2 AMD (29 Jan 2025)        cog-genomics.org/plink/2.0/\n",
      "(C) 2005-2025 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to /home/jupyter/COMT_AMPPD/AMPPD_COMT.coding_variants.log.\n",
      "Options in effect:\n",
      "  --export vcf-iid\n",
      "  --extract range /home/jupyter/COMT_AMPPD/COMT.coding_variants.variantstoKeep.txt\n",
      "  --out /home/jupyter/COMT_AMPPD/AMPPD_COMT.coding_variants\n",
      "  --pfile /home/jupyter/COMT_AMPPD/COMT\n",
      "\n",
      "Start time: Fri Mar 14 15:56:44 2025\n",
      "Note: --export 'vcf-iid' modifier is deprecated.  Use 'vcf' + 'id-paste=iid'.\n",
      "7445 MiB RAM detected, ~6013 available; reserving 3722 MiB for main workspace.\n",
      "Using up to 2 compute threads.\n",
      "5086 samples (2283 females, 2803 males; 5086 founders) loaded from\n",
      "/home/jupyter/COMT_AMPPD/COMT.psam.\n",
      "502 variants loaded from /home/jupyter/COMT_AMPPD/COMT.pvar.\n",
      "1 binary phenotype loaded (2251 cases, 2835 controls).\n",
      "--extract bed1: 498 variants excluded.\n",
      "4 variants remaining after main filters.\n",
      "--export vcf to /home/jupyter/COMT_AMPPD/AMPPD_COMT.coding_variants.vcf ...\n",
      "255075done.\n",
      "End time: Fri Mar 14 15:56:44 2025\n",
      "Running bgzip and tabix for coding_variants variants for AMP-PD\n",
      "Running plink to extract loss_of_function variants for AMP-PD\n",
      "PLINK v2.0.0-a.6.9LM AVX2 AMD (29 Jan 2025)        cog-genomics.org/plink/2.0/\n",
      "(C) 2005-2025 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to /home/jupyter/COMT_AMPPD/AMPPD_COMT.loss_of_function.log.\n",
      "Options in effect:\n",
      "  --export vcf-iid\n",
      "  --extract range /home/jupyter/COMT_AMPPD/COMT.loss_of_function.variantstoKeep.txt\n",
      "  --out /home/jupyter/COMT_AMPPD/AMPPD_COMT.loss_of_function\n",
      "  --pfile /home/jupyter/COMT_AMPPD/COMT\n",
      "\n",
      "Start time: Fri Mar 14 15:56:48 2025\n",
      "Note: --export 'vcf-iid' modifier is deprecated.  Use 'vcf' + 'id-paste=iid'.\n",
      "7445 MiB RAM detected, ~6030 available; reserving 3722 MiB for main workspace.\n",
      "Using up to 2 compute threads.\n",
      "5086 samples (2283 females, 2803 males; 5086 founders) loaded from\n",
      "/home/jupyter/COMT_AMPPD/COMT.psam.\n",
      "502 variants loaded from /home/jupyter/COMT_AMPPD/COMT.pvar.\n",
      "1 binary phenotype loaded (2251 cases, 2835 controls).\n",
      "--extract bed1: 502 variants excluded.\n",
      "Error: No variants remaining after main filters.\n",
      "End time: Fri Mar 14 15:56:48 2025\n",
      "Running bgzip and tabix for loss_of_function variants for AMP-PD\n",
      "[bgzip] No such file or directory: /home/jupyter/COMT_AMPPD/AMPPD_COMT.loss_of_function.vcf\n",
      "tbx_index_build failed: /home/jupyter/COMT_AMPPD/AMPPD_COMT.loss_of_function.vcf.gz\n"
     ]
    }
   ],
   "source": [
    "#Loop over 3 variant classes, extract variants and create the right format for RVTest\n",
    "variant_classes = ['potentially_functional', 'coding_variants','loss_of_function']\n",
    "\n",
    "WORK_DIR = f'/home/jupyter/COMT_AMPPD'\n",
    "\n",
    "for variant_class in variant_classes:\n",
    "    \n",
    "    # Print the command to be executed (for debugging purposes)\n",
    "    print(f'Running plink to extract {variant_class} variants for AMP-PD')\n",
    "    \n",
    "    #Extract relevant variants\n",
    "    ! /home/jupyter/tools/plink2 \\\n",
    "    --pfile {WORK_DIR}/COMT \\\n",
    "    --extract range {WORK_DIR}/COMT.{variant_class}.variantstoKeep.txt \\\n",
    "    --recode vcf-iid \\\n",
    "    --out {WORK_DIR}/AMPPD_COMT.{variant_class}\n",
    "    \n",
    "    # Print the command to be executed (for debugging purposes)\n",
    "    print(f'Running bgzip and tabix for {variant_class} variants for AMP-PD')\n",
    "        \n",
    "    ## Bgzip and Tabix (zip and index the file)\n",
    "    ! bgzip -f {WORK_DIR}/AMPPD_COMT.{variant_class}.vcf\n",
    "    ! tabix -f -p vcf {WORK_DIR}/AMPPD_COMT.{variant_class}.vcf.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Run RVTest for each variant class\n",
    "\n",
    "variant_classes = ['potentially_functional', 'coding_variants','loss_of_function']\n",
    "\n",
    "for variant_class in variant_classes:\n",
    "    \n",
    "    # Print the command to be executed (for debugging purposes)\n",
    "    print(f'Running RVtests for {variant_class} variants for AMP-PD')\n",
    "        \n",
    "     ## RVtests with covariates \n",
    "    #Make sure the pheno and covariate file starts with the first 5 columns: fid, iid, fatid, matid, sex\n",
    "    #The pheno-name flag only works when the pheno/covar file is structured properly\n",
    "    ! /home/jupyter/tools/rvtests/executable/rvtest --noweb --hide-covar \\\n",
    "    --out {WORK_DIR}/AMPPD_COMT.burden.{variant_class} \\\n",
    "    --kernel skat,skato \\\n",
    "    --inVcf {WORK_DIR}/AMPPD_COMT.{variant_class}.vcf.gz \\\n",
    "    --pheno {WORK_DIR}/AMPPD_EUR.COVS.txt \\\n",
    "    --pheno-name PHENO \\\n",
    "    --gene COMT \\\n",
    "    --geneFile {WORK_DIR}/refFlat.txt \\\n",
    "    --covar {WORK_DIR}/AMPPD_EUR.COVS.txt \\\n",
    "    --covar-name SEX,AGE,PC1,PC2,PC3,PC4,PC5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene\tRANGE\tN_INFORMATIVE\tNumVar\tNumPolyVar\tQ\tPvalue\tNumPerm\tActualPerm\tStat\tNumGreater\tNumEqual\tPermPvalue\r\n",
      "COMT\t22:19962552-19969975,22:19951517-19969975,22:19950901-19969975,22:19941771-19969975,22:19941771-19969975\t5086\t46\t46\t154675\t0.0597463\t10000\t10000\t154675\t713\t0\t0.0713\r\n"
     ]
    }
   ],
   "source": [
    "# Look at results for potentially functional variants \n",
    "! cat {WORK_DIR}/AMPPD_COMT.burden.potentially_functional.Skat.assoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene\tRANGE\tN_INFORMATIVE\tNumVar\tNumPolyVar\tQ\trho\tPvalue\r\n",
      "COMT\t22:19962552-19969975,22:19951517-19969975,22:19950901-19969975,22:19941771-19969975,22:19941771-19969975\t5086\t46\t46\t77337.6\t0\t0.108518\r\n"
     ]
    }
   ],
   "source": [
    "! cat {WORK_DIR}/AMPPD_COMT.burden.potentially_functional.SkatO.assoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene\tRANGE\tN_INFORMATIVE\tNumVar\tNumPolyVar\tQ\trho\tPvalue\r\n",
      "COMT\t22:19962552-19969975,22:19951517-19969975,22:19950901-19969975,22:19941771-19969975,22:19941771-19969975\t5086\t4\t4\t84.8181\t1\t0.78128\r\n"
     ]
    }
   ],
   "source": [
    "## Look at results for coding variants \n",
    "\n",
    "! cat {WORK_DIR}/AMPPD_COMT.burden.coding_variants.SkatO.assoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene\tRANGE\tN_INFORMATIVE\tNumVar\tNumPolyVar\tQ\tPvalue\tNumPerm\tActualPerm\tStat\tNumGreater\tNumEqual\tPermPvalue\r\n",
      "COMT\t22:19962552-19969975,22:19951517-19969975,22:19950901-19969975,22:19941771-19969975,22:19941771-19969975\t5086\t4\t4\t199.981\t0.82832\t10000\t1097\t199.981\t1000\t0\t0.911577\r\n"
     ]
    }
   ],
   "source": [
    "! cat {WORK_DIR}/AMPPD_COMT.burden.coding_variants.Skat.assoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Save to workspace bucket (move from VM to workspace bucket)\n",
    "variant_classes = ['potentially_functional', 'coding_variants','loss_of_function']\n",
    "\n",
    "for variant_class in variant_classes:\n",
    "    shell_do(f'gsutil -mu {BILLING_PROJECT_ID} cp -r {WORK_DIR}/AMPPD_COMT.burden.{variant_class}.*.assoc {WORKSPACE_BUCKET}/COMT_AMPPD/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case/Control Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### glm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\tchr22:19941423:G:A\t0\t19941423\tA\tG\r\n",
      "22\tchr22:19941469:G:A\t0\t19941469\tA\tG\r\n",
      "22\tchr22:19941499:G:A\t0\t19941499\tA\tG\r\n",
      "22\tchr22:19941618:T:TG\t0\t19941618\tTG\tT\r\n",
      "22\tchr22:19941620:G:A\t0\t19941620\tA\tG\r\n",
      "22\tchr22:19941630:C:T\t0\t19941630\tT\tC\r\n",
      "22\tchr22:19941640:C:T\t0\t19941640\tT\tC\r\n",
      "22\tchr22:19941662:G:T\t0\t19941662\tT\tG\r\n",
      "22\tchr22:19941740:C:T\t0\t19941740\tT\tC\r\n",
      "22\tchr22:19941872:G:C\t0\t19941872\tC\tG\r\n"
     ]
    }
   ],
   "source": [
    "# Check format\n",
    "WORK_DIR = f'/home/jupyter/COMT_AMPPD'\n",
    "\n",
    "!head {WORK_DIR}/COMT.bim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v2.0.0-a.6.9LM AVX2 AMD (29 Jan 2025)        cog-genomics.org/plink/2.0/\n",
      "(C) 2005-2025 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to /home/jupyter/COMT_AMPPD/AMPPD_COMT.allvariants.log.\n",
      "Options in effect:\n",
      "  --adjust\n",
      "  --bfile /home/jupyter/COMT_AMPPD/COMT\n",
      "  --ci 0.95\n",
      "  --covar /home/jupyter/COMT_AMPPD/AMPPD_EUR.COVS.txt\n",
      "  --covar-name SEX,AGE,PC1,PC2,PC3,PC4,PC5\n",
      "  --covar-variance-standardize\n",
      "  --geno 0.05\n",
      "  --glm\n",
      "  --hwe 0.0001\n",
      "  --mac 2\n",
      "  --maf 0.01\n",
      "  --out /home/jupyter/COMT_AMPPD/AMPPD_COMT.allvariants\n",
      "\n",
      "Start time: Tue Apr  1 14:51:30 2025\n",
      "7445 MiB RAM detected, ~6059 available; reserving 3722 MiB for main workspace.\n",
      "Using up to 2 compute threads.\n",
      "5086 samples (2283 females, 2803 males; 5086 founders) loaded from\n",
      "/home/jupyter/COMT_AMPPD/COMT.fam.\n",
      "502 variants loaded from /home/jupyter/COMT_AMPPD/COMT.bim.\n",
      "1 binary phenotype loaded (2251 cases, 2835 controls).\n",
      "7 covariates loaded from /home/jupyter/COMT_AMPPD/AMPPD_EUR.COVS.txt.\n",
      "--covar-variance-standardize: 7 covariates transformed.\n",
      "Calculating allele frequencies... done.\n",
      "--geno: 0 variants removed due to missing genotype data.\n",
      "--hwe: 1 variant removed due to Hardy-Weinberg exact test (founders only).\n",
      "381 variants removed due to allele frequency threshold(s)\n",
      "(--maf/--max-maf/--mac/--max-mac).\n",
      "120 variants remaining after main filters.\n",
      "--glm logistic-Firth hybrid regression on phenotype 'PHENO1': done.\n",
      "Results written to /home/jupyter/COMT_AMPPD/AMPPD_COMT.allvariants.PHENO1.glm.logistic.hybrid .\n",
      "--adjust: Genomic inflation est. lambda (based on median chisq) = 1.86797.\n",
      "--adjust values (120 tests) written to\n",
      "/home/jupyter/COMT_AMPPD/AMPPD_COMT.allvariants.PHENO1.glm.logistic.hybrid.adjusted\n",
      ".\n",
      "End time: Tue Apr  1 14:51:31 2025\n"
     ]
    }
   ],
   "source": [
    "#Run glm with covariates. We used a0-ref to do the regression on the right allele for rs4680.\n",
    "#From the 16 Feb 2018 (alpha 2) entry in the version history: \n",
    "#\"Also, --glm now defaults to regressing on minor instead of ALT allele dosages \n",
    "#(this can be overridden with 'a0-ref').\"\n",
    "\n",
    "\n",
    "WORK_DIR = f'/home/jupyter/COMT_AMPPD'\n",
    "\n",
    "! /home/jupyter/tools/plink2 \\\n",
    "--bfile {WORK_DIR}/COMT \\\n",
    "--glm \\\n",
    "--adjust \\\n",
    "--ci 0.95 \\\n",
    "--mac 2 \\\n",
    "--geno 0.05 \\\n",
    "--maf 0.01 \\\n",
    "--hwe 0.0001 \\\n",
    "--covar {WORK_DIR}/AMPPD_EUR.COVS.txt \\\n",
    "--covar-name SEX,AGE,PC1,PC2,PC3,PC4,PC5 \\\n",
    "--covar-variance-standardize \\\n",
    "--out {WORK_DIR}/AMPPD_COMT.allvariants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_glm = pd.read_csv(f'{WORK_DIR}/AMPPD_COMT.allvariants.PHENO1.glm.logistic.hybrid', delim_whitespace=True)\n",
    "results_glm_add=results_glm[(results_glm['TEST']=='ADD')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_glm_adj = pd.read_csv(f'{WORK_DIR}/AMPPD_COMT.allvariants.PHENO1.glm.logistic.hybrid.adjusted', delim_whitespace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add more info to the glm results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v1.90b6.9 64-bit (4 Mar 2019)            www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2019 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to /home/jupyter/COMT_AMPPD/AMPPD_COMT.AllVariants.adj.log.\n",
      "Options in effect:\n",
      "  --bfile /home/jupyter/COMT_AMPPD/COMT\n",
      "  --out /home/jupyter/COMT_AMPPD/AMPPD_COMT.AllVariants.adj\n",
      "  --recode A\n",
      "\n",
      "7445 MB RAM detected; reserving 3722 MB for main workspace.\n",
      "502 variants loaded from .bim file.\n",
      "5086 people (2803 males, 2283 females) loaded from .fam.\n",
      "5086 phenotype values loaded from .fam.\n",
      "Using 1 thread (no multithreaded calculations invoked).\n",
      "Before main variant filters, 5086 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Total genotyping rate is 0.999957.\n",
      "502 variants and 5086 people pass filters and QC.\n",
      "Among remaining phenotypes, 2251 are cases and 2835 are controls.\n",
      "--recode A to /home/jupyter/COMT_AMPPD/AMPPD_COMT.AllVariants.adj.raw ... 101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899done.\n"
     ]
    }
   ],
   "source": [
    "#--recode A creates a new text fileset, showing each variant in each case and control for the minor allele (A).\n",
    "# Also extract the significant variants \n",
    "! /home/jupyter/tools/plink \\\n",
    "--bfile {WORK_DIR}/COMT \\\n",
    "--recode A \\\n",
    "--out {WORK_DIR}/AMPPD_COMT.AllVariants.adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "recode = pd.read_csv(f'{WORK_DIR}/AMPPD_COMT.AllVariants.adj.raw', delim_whitespace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variants in AMPPD for COMT: 502\n"
     ]
    }
   ],
   "source": [
    "# Make a list from the column names\n",
    "column_names = recode.columns.tolist()\n",
    "\n",
    "# Drop the first 6 columns to keep the variants \n",
    "variants = column_names[6:]\n",
    "\n",
    "print(f'Number of variants in AMPPD for COMT: {len(variants)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-filter the dataset\n",
    "cases_data = recode[recode['PHENOTYPE'] == 2]\n",
    "controls_data = recode[recode['PHENOTYPE'] == 1]\n",
    "total_cases = cases_data.shape[0]\n",
    "total_controls = controls_data.shape[0]\n",
    "results = []\n",
    "\n",
    "\n",
    "for variant in variants:\n",
    "        hom_cases = (cases_data[variant] == 2).sum()\n",
    "        het_cases = (cases_data[variant] == 1).sum()\n",
    "        hom_ref_cases = (cases_data[variant] == 0).sum()  # Homozygous reference genotype\n",
    "        missing_cases = total_cases - (hom_cases + het_cases + hom_ref_cases)  # Missing data count\n",
    "        freq_cases = (2 * hom_cases + het_cases) / (2 * (total_cases - missing_cases))  # Adjust for missing data in denominator\n",
    "\n",
    "        ## For controls\n",
    "        hom_controls = (controls_data[variant] == 2).sum()\n",
    "        het_controls = (controls_data[variant] == 1).sum()\n",
    "        hom_ref_controls = (controls_data[variant] == 0).sum()  # Homozygous reference genotype\n",
    "        missing_controls = total_controls - (hom_controls + het_controls + hom_ref_controls)  # Missing data count\n",
    "        freq_controls = (2 * hom_controls + het_controls) / (2 * (total_controls - missing_controls))  # Adjust for missing data in denominator\n",
    "    \n",
    "        # Append results in dictionary format\n",
    "        results.append({\n",
    "            'Variant': variant,\n",
    "            'Hom Cases': hom_cases,\n",
    "            'Het Cases': het_cases,\n",
    "            'Hom Ref Cases': hom_ref_cases,\n",
    "            'Missing Cases': missing_cases,\n",
    "            'Total Cases': total_cases,\n",
    "            'Carrier Freq in Cases': freq_cases,\n",
    "            'Hom Controls': hom_controls,\n",
    "            'Het Controls': het_controls,\n",
    "            'Hom Ref Controls': hom_ref_controls,\n",
    "            'Missing Controls': missing_controls,\n",
    "            'Total Controls': total_controls,\n",
    "            'Carrier Freq in Controls': freq_controls\n",
    "        })\n",
    "\n",
    "# Return\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results['ID'] = df_results['Variant'].apply(lambda x: x.rsplit('_', 1)[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge with the glm file\n",
    "results_glm_add_merge = results_glm_add[['ID','A1','OR','L95','U95','P']]\n",
    "merged = pd.merge(df_results, results_glm_add_merge, on='ID', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to CSV\n",
    "merged.to_csv(f'{WORK_DIR}/AMPPD_COMT_AllVariants.glm.txt', sep = '\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final results to workspace bucket (move from VM to workspace bucket)\n",
    "shell_do(f'gsutil -mu {BILLING_PROJECT_ID} cp -r {WORK_DIR}/AMPPD_COMT_AllVariants.glm.txt {WORKSPACE_BUCKET}/COMT_AMPPD/AMPPD_COMT_allvariants_minusintronic.glm.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinical scales Association Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download clinical data: MOCA scale\n",
    "shell_do(f'gsutil -u {BILLING_PROJECT_ID} -m cp -r {AMP_CLINICAL_RELEASE_PATH}/MOCA.csv {WORK_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also re-use the AMPPD covariate file used before\n",
    "AMPPD_COV = pd.read_csv(f'{WORK_DIR}/AMPPD_EUR.COVS.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PHENO\n",
       "1    2835\n",
       "2    2251\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AMPPD_COV['PHENO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another source of data is the Demographic.csv file, to obtain the education level. Note that we will use baseline\n",
    "education = pd.read_csv(f'{WORK_DIR}/Demographics.csv')\n",
    "education = education[['participant_id','visit_month','visit_name','education_level_years']]\n",
    "education_M0 = education[education['visit_month']==0]\n",
    "education_M0 = education_M0[['participant_id','education_level_years']]\n",
    "education_M0.columns = ['IID','education_level_years']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now read the MOCA.csv file and format it to only contain baseline and the selected columns\n",
    "moca_df = pd.read_csv(f'{WORK_DIR}/MOCA.csv')\n",
    "moca_df = moca_df[['participant_id','visit_month','moca_total_score']]\n",
    "moca_m0_df = moca_df[moca_df['visit_month']==0] \n",
    "moca_m0_df.columns = ['IID','visit_name','moca_total_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with the COV file and then include also the education data\n",
    "AMPPD_COV_moca = pd.merge(moca_m0_df,AMPPD_COV,on=\"IID\")\n",
    "AMPPD_COV_moca_education = pd.merge(AMPPD_COV_moca,education_M0,on='IID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PHENO\n",
       "2    1349\n",
       "1     495\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the values of PHENO\n",
    "AMPPD_COV_moca_education['PHENO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMPPD_COV_moca_education = AMPPD_COV_moca_education.drop_duplicates(subset=['IID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns\n",
    "AMPPD_COV_moca_education = AMPPD_COV_moca_education[['IID','IID','AGE','PHENO','SEX','education_level_years','moca_total_score','PC1','PC2','PC3','PC4','PC5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "AMPPD_COV_moca_education.columns = ['FID','IID','AGE','PHENO','SEX','Education_years','moca_total_score','PC1','PC2','PC3','PC4','PC5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Education_years\n",
       "1     1041\n",
       "2      498\n",
       "-9     258\n",
       "0       39\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reformat education years\n",
    "AMPPD_COV_moca_education['Education_years'] = AMPPD_COV_moca_education['Education_years'].replace({'Unknown': '-9'})\n",
    "AMPPD_COV_moca_education['Education_years'] = AMPPD_COV_moca_education['Education_years'].replace({'Less than 12 years': '0'})\n",
    "AMPPD_COV_moca_education['Education_years'] = AMPPD_COV_moca_education['Education_years'].replace({'12-16 years': '1'})\n",
    "AMPPD_COV_moca_education['Education_years'] = AMPPD_COV_moca_education['Education_years'].replace({'Greater than 16 years': '2'})\n",
    "AMPPD_COV_moca_education['Education_years'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are testing the association of the variants with MOCA total score on PD patients\n",
    "AMPPD_COV_moca_education_EP=AMPPD_COV_moca_education[AMPPD_COV_moca_education['PHENO']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save on a file \n",
    "AMPPD_COV_moca_education_EP.to_csv(f'{WORK_DIR}/COVAR_MOCA_EP.txt',sep=\"\\t\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v2.0.0-a.6.9LM AVX2 AMD (29 Jan 2025)        cog-genomics.org/plink/2.0/\n",
      "(C) 2005-2025 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to /home/jupyter/COMT_AMPPD/MOCA_COMT_All_variants.log.\n",
      "Options in effect:\n",
      "  --adjust\n",
      "  --bfile /home/jupyter/COMT_AMPPD/COMT\n",
      "  --covar /home/jupyter/COMT_AMPPD/COVAR_MOCA_EP.txt\n",
      "  --covar-name SEX,AGE,Education_years,PC1,PC2,PC3,PC4,PC5\n",
      "  --covar-variance-standardize\n",
      "  --geno 0.05\n",
      "  --glm a0-ref\n",
      "  --hwe 0.0001\n",
      "  --mac 2\n",
      "  --maf 0.01\n",
      "  --out /home/jupyter/COMT_AMPPD/MOCA_COMT_All_variants\n",
      "  --pheno /home/jupyter/COMT_AMPPD/COVAR_MOCA_EP.txt\n",
      "  --pheno-name moca_total_score\n",
      "\n",
      "Start time: Tue Apr  1 14:52:00 2025\n",
      "7445 MiB RAM detected, ~6059 available; reserving 3722 MiB for main workspace.\n",
      "Using up to 2 compute threads.\n",
      "5086 samples (2283 females, 2803 males; 5086 founders) loaded from\n",
      "/home/jupyter/COMT_AMPPD/COMT.fam.\n",
      "502 variants loaded from /home/jupyter/COMT_AMPPD/COMT.bim.\n",
      "1 quantitative phenotype loaded (1341 values).\n",
      "8 covariates loaded from /home/jupyter/COMT_AMPPD/COVAR_MOCA_EP.txt.\n",
      "--covar-variance-standardize: 8 covariates transformed.\n",
      "Calculating allele frequencies... done.\n",
      "--geno: 0 variants removed due to missing genotype data.\n",
      "--hwe: 1 variant removed due to Hardy-Weinberg exact test (founders only).\n",
      "381 variants removed due to allele frequency threshold(s)\n",
      "(--maf/--max-maf/--mac/--max-mac).\n",
      "120 variants remaining after main filters.\n",
      "--glm linear regression on phenotype 'moca_total_score': done.\n",
      "Results written to /home/jupyter/COMT_AMPPD/MOCA_COMT_All_variants.moca_total_score.glm.linear .\n",
      "--adjust: Genomic inflation est. lambda (based on median chisq) = 1.36358.\n",
      "--adjust values (120 tests) written to\n",
      "/home/jupyter/COMT_AMPPD/MOCA_COMT_All_variants.moca_total_score.glm.linear.adjusted\n",
      ".\n",
      "End time: Tue Apr  1 14:52:00 2025\n"
     ]
    }
   ],
   "source": [
    "# Test the association for all variants of the gene detected with MOCA scale total score\n",
    "WORK_DIR = f'/home/jupyter/COMT_AMPPD'\n",
    "\n",
    "! /home/jupyter/tools/plink2 \\\n",
    "--bfile {WORK_DIR}/COMT \\\n",
    "--glm a0-ref\\\n",
    "--pheno {WORK_DIR}/COVAR_MOCA_EP.txt \\\n",
    "--pheno-name moca_total_score \\\n",
    "--adjust \\\n",
    "--mac 2 \\\n",
    "--hwe 0.0001 \\\n",
    "--geno 0.05 \\\n",
    "--maf 0.01 \\\n",
    "--covar {WORK_DIR}/COVAR_MOCA_EP.txt \\\n",
    "--covar-name SEX,AGE,Education_years,PC1,PC2,PC3,PC4,PC5 \\\n",
    "--covar-variance-standardize \\\n",
    "--out {WORK_DIR}/MOCA_COMT_All_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_MOCA_AllVariants = pd.read_csv(f'{WORK_DIR}/MOCA_COMT_All_variants.moca_total_score.glm.linear', delim_whitespace=True)\n",
    "glm_MOCA_AllVariants_ADD = glm_MOCA_AllVariants[glm_MOCA_AllVariants['TEST']==\"ADD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also check the P corrected for multiple comparison\n",
    "glm_MOCA_AllVariants_adjusted= pd.read_csv(f'{WORK_DIR}/MOCA_COMT_All_variants.moca_total_score.glm.linear.adjusted', delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results of the glm to a file\n",
    "glm_MOCA_AllVariants_ADD.to_csv(f'{WORK_DIR}/MOCA_COMT.AllVariants.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDS UPDRS III\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download clinical data: MDS-UPDRS scale part III\n",
    "shell_do(f'gsutil -u {BILLING_PROJECT_ID} -m cp -r {AMP_CLINICAL_RELEASE_PATH}/MDS_UPDRS_Part_III.csv {WORK_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-use the COV file (demographics of case-control samples)\n",
    "AMPPD_COV = pd.read_csv(f'{WORK_DIR}/AMPPD_EUR.COVS.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now read the MDS_UPDRS_PART_III.csv file and \n",
    "# format it to only contain baseline and the selected columns\n",
    "mds_updrs_iii = pd.read_csv(f'{WORK_DIR}/MDS_UPDRS_Part_III.csv')\n",
    "mds_updrs_iii = mds_updrs_iii[['participant_id','visit_month','mds_updrs_part_iii_summary_score']]\n",
    "mds_updrs_iii_m0 = mds_updrs_iii[mds_updrs_iii['visit_month']==0] \n",
    "mds_updrs_iii_m0.columns = ['IID','visit_month','MDS_UPDRS_III']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PHENO\n",
       "2    2193\n",
       "1     646\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge with the COV file and check the sample size\n",
    "AMPPD_COV_UPDRSIII = pd.merge(mds_updrs_iii_m0,AMPPD_COV,on=\"IID\")\n",
    "AMPPD_COV_UPDRSIII['PHENO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns\n",
    "AMPPD_COV_UPDRSIII = AMPPD_COV_UPDRSIII[['IID','IID','AGE','PHENO','SEX','MDS_UPDRS_III','PC1','PC2','PC3','PC4','PC5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "AMPPD_COV_UPDRSIII.columns = ['FID','IID','AGE','PHENO','SEX','MDS_UPDRS_III','PC1','PC2','PC3','PC4','PC5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat the interest column to numeric\n",
    "AMPPD_COV_UPDRSIII[\"MDS_UPDRS_III\"] = pd.to_numeric(AMPPD_COV_UPDRSIII[\"MDS_UPDRS_III\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data on PD and HC\n",
    "AMPPD_COV_UPDRSIII_EP=AMPPD_COV_UPDRSIII[AMPPD_COV_UPDRSIII['PHENO']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_79/2200475102.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  AMPPD_COV_UPDRSIII_EP['MDS_UPDRS_III'] = AMPPD_COV_UPDRSIII_EP['MDS_UPDRS_III'].fillna(-9)\n"
     ]
    }
   ],
   "source": [
    "# Check NAs and fill with -9\n",
    "AMPPD_COV_UPDRSIII_EP['MDS_UPDRS_III'] = AMPPD_COV_UPDRSIII_EP['MDS_UPDRS_III'].fillna(-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to a file\n",
    "AMPPD_COV_UPDRSIII_EP.to_csv(f'{WORK_DIR}/COVAR_MDS_UPDRS_III_EP.txt',sep=\"\\t\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v2.0.0-a.6.9LM AVX2 AMD (29 Jan 2025)        cog-genomics.org/plink/2.0/\n",
      "(C) 2005-2025 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to /home/jupyter/COMT_AMPPD/MDS_UPDRS_III_COMT_All_variants.log.\n",
      "Options in effect:\n",
      "  --adjust\n",
      "  --bfile /home/jupyter/COMT_AMPPD/COMT\n",
      "  --covar /home/jupyter/COMT_AMPPD/COVAR_MDS_UPDRS_III_EP.txt\n",
      "  --covar-name SEX,AGE,PC1,PC2,PC3,PC4,PC5\n",
      "  --covar-variance-standardize\n",
      "  --geno 0.05\n",
      "  --glm a0-ref\n",
      "  --hwe 0.0001\n",
      "  --mac 2\n",
      "  --maf 0.01\n",
      "  --out /home/jupyter/COMT_AMPPD/MDS_UPDRS_III_COMT_All_variants\n",
      "  --pheno /home/jupyter/COMT_AMPPD/COVAR_MDS_UPDRS_III_EP.txt\n",
      "  --pheno-name MDS_UPDRS_III\n",
      "\n",
      "Start time: Tue Apr  1 14:52:11 2025\n",
      "7445 MiB RAM detected, ~6057 available; reserving 3722 MiB for main workspace.\n",
      "Using up to 2 compute threads.\n",
      "5086 samples (2283 females, 2803 males; 5086 founders) loaded from\n",
      "/home/jupyter/COMT_AMPPD/COMT.fam.\n",
      "502 variants loaded from /home/jupyter/COMT_AMPPD/COMT.bim.\n",
      "1 quantitative phenotype loaded (1666 values).\n",
      "7 covariates loaded from /home/jupyter/COMT_AMPPD/COVAR_MDS_UPDRS_III_EP.txt.\n",
      "--covar-variance-standardize: 7 covariates transformed.\n",
      "Calculating allele frequencies... done.\n",
      "--geno: 0 variants removed due to missing genotype data.\n",
      "--hwe: 1 variant removed due to Hardy-Weinberg exact test (founders only).\n",
      "381 variants removed due to allele frequency threshold(s)\n",
      "(--maf/--max-maf/--mac/--max-mac).\n",
      "120 variants remaining after main filters.\n",
      "--glm linear regression on phenotype 'MDS_UPDRS_III': done.\n",
      "Results written to /home/jupyter/COMT_AMPPD/MDS_UPDRS_III_COMT_All_variants.MDS_UPDRS_III.glm.linear .\n",
      "--adjust: Genomic inflation est. lambda (based on median chisq) = 1.25342.\n",
      "--adjust values (120 tests) written to\n",
      "/home/jupyter/COMT_AMPPD/MDS_UPDRS_III_COMT_All_variants.MDS_UPDRS_III.glm.linear.adjusted\n",
      ".\n",
      "End time: Tue Apr  1 14:52:11 2025\n"
     ]
    }
   ],
   "source": [
    "# Test the association for all variants of the gene detected with UPDRSIII scale total score\n",
    "\n",
    "WORK_DIR = f'/home/jupyter/COMT_AMPPD'\n",
    "\n",
    "! /home/jupyter/tools/plink2 \\\n",
    "--bfile {WORK_DIR}/COMT \\\n",
    "--glm a0-ref\\\n",
    "--pheno {WORK_DIR}/COVAR_MDS_UPDRS_III_EP.txt \\\n",
    "--pheno-name MDS_UPDRS_III \\\n",
    "--adjust \\\n",
    "--mac 2 \\\n",
    "--geno 0.05 \\\n",
    "--hwe 0.0001 \\\n",
    "--maf 0.01 \\\n",
    "--covar {WORK_DIR}/COVAR_MDS_UPDRS_III_EP.txt \\\n",
    "--covar-name SEX,AGE,PC1,PC2,PC3,PC4,PC5 \\\n",
    "--covar-variance-standardize \\\n",
    "--out {WORK_DIR}/MDS_UPDRS_III_COMT_All_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_UPDRSIII_AllVariants = pd.read_csv(f'{WORK_DIR}/MDS_UPDRS_III_COMT_All_variants.MDS_UPDRS_III.glm.linear', delim_whitespace=True)\n",
    "glm_UPDRSIII_AllVariants_ADD = glm_UPDRSIII_AllVariants[glm_UPDRSIII_AllVariants['TEST']==\"ADD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results of the glm to a file\n",
    "glm_UPDRSIII_AllVariants_ADD.to_csv(f'{WORK_DIR}/UPDRSIV_COMT.AllVariants.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also check the P corrected for multiple comparison\n",
    "\n",
    "glm_UPDRSIII_adj = pd.read_csv(f'{WORK_DIR}/MDS_UPDRS_III_COMT_All_variants.MDS_UPDRS_III.glm.linear.adjusted', delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDS UPDRS IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download clinical data: MDS-UPDRS scale part III\n",
    "shell_do(f'gsutil -u {BILLING_PROJECT_ID} -m cp -r {AMP_CLINICAL_RELEASE_PATH}/MDS_UPDRS_Part_IV.csv {WORK_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the MDS_UPDRS_PART_IV.csv file and \n",
    "# format it to only contain baseline and the selected columns\n",
    "mds_updrs_iv = pd.read_csv(f'{WORK_DIR}/MDS_UPDRS_Part_IV.csv')\n",
    "mds_updrs_iv = mds_updrs_iv[['participant_id','visit_month','mds_updrs_part_iv_summary_score']]\n",
    "mds_updrs_iv_m0 = mds_updrs_iv[mds_updrs_iv['visit_month']==0] \n",
    "mds_updrs_iv_m0.columns = ['IID','visit_month','MDS_UPDRS_IV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with the COV file and check the sample size\n",
    "AMPPD_COV_UPDRSIV= pd.merge(mds_updrs_iv_m0,AMPPD_COV,on=\"IID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns\n",
    "AMPPD_COV_UPDRSIV = AMPPD_COV_UPDRSIV[['IID','IID','AGE','PHENO','SEX','MDS_UPDRS_IV','PC1','PC2','PC3','PC4','PC5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "AMPPD_COV_UPDRSIV.columns = ['FID','IID','AGE','PHENO','SEX','MDS_UPDRS_IV','PC1','PC2','PC3','PC4','PC5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat the interest column to numeric\n",
    "AMPPD_COV_UPDRSIV[\"MDS_UPDRS_IV\"] = pd.to_numeric(AMPPD_COV_UPDRSIV[\"MDS_UPDRS_IV\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data on PD and HC\n",
    "AMPPD_COV_UPDRSIV_EP=AMPPD_COV_UPDRSIV[AMPPD_COV_UPDRSIV['PHENO']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check NAs and fill with -9\n",
    "AMPPD_COV_UPDRSIV_EP['MDS_UPDRS_V'] = AMPPD_COV_UPDRSIV_EP['MDS_UPDRS_IV'].fillna(-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to a file\n",
    "AMPPD_COV_UPDRSIV_EP.to_csv(f'{WORK_DIR}/COVAR_MDS_UPDRS_IV_EP.txt',sep=\"\\t\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v2.0.0-a.6.9LM AVX2 AMD (29 Jan 2025)        cog-genomics.org/plink/2.0/\n",
      "(C) 2005-2025 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to /home/jupyter/COMT_AMPPD/MDS_UPDRS_IV_COMT_All_variants.log.\n",
      "Options in effect:\n",
      "  --adjust\n",
      "  --bfile /home/jupyter/COMT_AMPPD/COMT\n",
      "  --covar /home/jupyter/COMT_AMPPD/COVAR_MDS_UPDRS_IV_EP.txt\n",
      "  --covar-name SEX,AGE,PC1,PC2,PC3,PC4,PC5\n",
      "  --covar-variance-standardize\n",
      "  --geno 0.05\n",
      "  --glm a0-ref\n",
      "  --hwe 0.0001\n",
      "  --mac 2\n",
      "  --maf 0.01\n",
      "  --out /home/jupyter/COMT_AMPPD/MDS_UPDRS_IV_COMT_All_variants\n",
      "  --pheno /home/jupyter/COMT_AMPPD/COVAR_MDS_UPDRS_IV_EP.txt\n",
      "  --pheno-name MDS_UPDRS_IV\n",
      "\n",
      "Start time: Tue Apr  1 14:52:18 2025\n",
      "7445 MiB RAM detected, ~6053 available; reserving 3722 MiB for main workspace.\n",
      "Using up to 2 compute threads.\n",
      "5086 samples (2283 females, 2803 males; 5086 founders) loaded from\n",
      "/home/jupyter/COMT_AMPPD/COMT.fam.\n",
      "502 variants loaded from /home/jupyter/COMT_AMPPD/COMT.bim.\n",
      "1 quantitative phenotype loaded (1794 values).\n",
      "7 covariates loaded from /home/jupyter/COMT_AMPPD/COVAR_MDS_UPDRS_IV_EP.txt.\n",
      "--covar-variance-standardize: 7 covariates transformed.\n",
      "Calculating allele frequencies... done.\n",
      "--geno: 0 variants removed due to missing genotype data.\n",
      "--hwe: 1 variant removed due to Hardy-Weinberg exact test (founders only).\n",
      "381 variants removed due to allele frequency threshold(s)\n",
      "(--maf/--max-maf/--mac/--max-mac).\n",
      "120 variants remaining after main filters.\n",
      "--glm linear regression on phenotype 'MDS_UPDRS_IV': done.\n",
      "Results written to /home/jupyter/COMT_AMPPD/MDS_UPDRS_IV_COMT_All_variants.MDS_UPDRS_IV.glm.linear .\n",
      "--adjust: Genomic inflation est. lambda (based on median chisq) = 1.60665.\n",
      "--adjust values (120 tests) written to\n",
      "/home/jupyter/COMT_AMPPD/MDS_UPDRS_IV_COMT_All_variants.MDS_UPDRS_IV.glm.linear.adjusted\n",
      ".\n",
      "End time: Tue Apr  1 14:52:18 2025\n"
     ]
    }
   ],
   "source": [
    "# Test the association for all variants of the gene detected with UPDRSIV scale total score\n",
    "\n",
    "WORK_DIR = f'/home/jupyter/COMT_AMPPD'\n",
    "\n",
    "! /home/jupyter/tools/plink2 \\\n",
    "--bfile {WORK_DIR}/COMT \\\n",
    "--glm a0-ref\\\n",
    "--pheno {WORK_DIR}/COVAR_MDS_UPDRS_IV_EP.txt \\\n",
    "--pheno-name MDS_UPDRS_IV \\\n",
    "--adjust \\\n",
    "--mac 2 \\\n",
    "--geno 0.05 \\\n",
    "--maf 0.01 \\\n",
    "--hwe 0.0001 \\\n",
    "--covar {WORK_DIR}/COVAR_MDS_UPDRS_IV_EP.txt \\\n",
    "--covar-name SEX,AGE,PC1,PC2,PC3,PC4,PC5 \\\n",
    "--covar-variance-standardize \\\n",
    "--out {WORK_DIR}/MDS_UPDRS_IV_COMT_All_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_UPDRSIV_AllVariants = pd.read_csv(f'{WORK_DIR}/MDS_UPDRS_IV_COMT_All_variants.MDS_UPDRS_IV.glm.linear', delim_whitespace=True)\n",
    "glm_UPDRSIV_AllVariants_ADD= glm_UPDRSIV_AllVariants[glm_UPDRSIV_AllVariants['TEST']==\"ADD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results of the glm to a file\n",
    "glm_UPDRSIV_AllVariants_ADD.to_csv(f'{WORK_DIR}/UPDRSIV_COMT.AllVariants.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also check the P corrected for multiple comparison\n",
    "\n",
    "glm_UPDRSIV_AllVariants_adj = pd.read_csv(f'{WORK_DIR}/MDS_UPDRS_IV_COMT_All_variants.MDS_UPDRS_IV.glm.linear.adjusted', delim_whitespace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
